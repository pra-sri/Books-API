# PRAKHAR SRIVASTAVA
*Data Engineer | Hadoop, Hive, Spark, Python, PySpark, SQL*

## PROFILE SUMMARY
- **Professional Summary**: Data Engineer with 2.8 years of hands-on experience in the tech industry. Proven track record in designing, developing, and deploying complex data pipelines using Python, SQL, PySpark, Hadoop, and Scala. Adept at data ingestion, transformation, and analysis with a strong aptitude for problem-solving.

## EDUCATION
- **Bachelor of Technology (B.Tech/B.E.)**
  - *Computers*
  - Dr. A.P.J. Abdul Kalam Technical University
  - Year of Passing: 2020
  - *GPA*: 79.8%

- **Class XII**
  - *Central Board of Secondary Education (CBSE)*
  - Year of Passing: 2016
  - *GPA Range*: 75-79.9%

- **Class X**
  - *Council for the Indian School Certificate Examinations (CISCE/ICSE/ISC)*
  - Year of Passing: 2014
  - *GPA Range*: 70-74.9%

## WORK EXPERIENCE
**Big Data Engineer | Infosys**
*April 2021 - Present*

### Project: POLO Ralph Lauren (March '22 - Present)
- **Data Reconciliation**
  - *Business Impact*: Identifying data discrepancies between source and target.
  - *Responsibilities*: Conducting ETL processes on source data and generating variance reports by comparing source and target data.
  - *Technologies Used*: Python, AWS S3, AWS Redshift, Apache Airflow, SQL, PySpark

- **S3 as a DB**
  - *Business Impact*: Achieved cost savings and performance improvements.
  - *Responsibilities*: Successfully migrated non-transactional data from Aurora to S3 with partitioning. Modified and integrated AWS S3 into the framework's code, replacing Aurora based on the new partitioned data.
  - *Technologies Used*: AWS Aurora, AWS S3, Python

- **Automate Service NOW Incident**
  - *Business Impact*: Reduced manual effort and dependency.
  - *Responsibilities*: Automated the creation of incidents using SNOW RESTful APIs, reducing manual intervention.
  - *Technologies Used*: Service NOW, Python

### Project: Edeka Digital (April '21 - March '22)
- **Data Ingestion**
  - *Responsibilities*: Oversaw data ingestion processes, fetching data, performing operations, and creating reports based on business rules.
  - *Technologies Used*: Python, PySpark, SQL, Azure Databricks

**Big Data Trainee | Infosys**
*January 2021 - March 2021*
- Underwent comprehensive training in a diverse stack, including Hadoop, MapReduce Programming, HIVE, Scala, Apache Spark, Python, and PySpark.

## TECHNICAL SKILLS
- **Languages**: Python, SQL, SCALA, Java
- **Big Data Tools**: Hadoop, Hive, Spark Core, PySpark, MapReduce
- **Data Structures**: Proficient in data structures and algorithms
- **Web Development**: Familiarity with Spring Boot

## LANGUAGES KNOWN
- *English*: Proficient
- *Hindi*: Native Speaker

## CERTIFICATIONS
- **Infosys Certified Big Data Developer**
- **Infosys Certified Spark Professional**
- **Infosys Certified Python Programmer**

## PERSONAL DETAILS
- *Total Experience*: 2 Years
- 
