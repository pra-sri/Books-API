**PRAKHAR SRIVASTAVA**
*Data Engineer | Hadoop, Hive, Spark, Python, PySpark, SQL*

**PROFILE SUMMARY**
Data Engineer with 2.8 years of experience in the tech industry, specializing in the design, development, and deployment of data pipelines using Python, SQL, PySpark, Hadoop, and Scala. Proven expertise in data ingestion, transformation, and analysis, complemented by strong problem-solving and analytical skills.

**EDUCATION HISTORY**
- *Bachelor of Technology (B.Tech/B.E.)* in Computers
  - Dr. A.P.J. Abdul Kalam Technical University
  - Graduated in 2020 with a GPA of 79.8%

- *Class XII*
  - Central Board of Secondary Education (CBSE)
  - Completed in 2016 with a GPA in the range of 75-79.9%

- *Class X*
  - Council for the Indian School Certificate Examinations (CISCE/ICSE/ISC)
  - Completed in 2014 with a GPA in the range of 70-74.9%

**CONTACT INFORMATION**
- *Mobile*: +91-9695631011
- *Email*: prakhar740@gmail.com

**PERSONAL DETAILS**
- *Total Experience*: 2 Years 8 Months
- *Current Location*: Gurgaon/Gurugram
- *Date of Birth*: July 16, 1998
- *Gender*: Male

**TECHNICAL SKILLS**
- Python
- Pyspark
- SQL
- Mapreduce
- Spark Core
- Hive
- Data Structures
- SCALA
- Java
- Spring Boot

**LANGUAGES KNOWN**
- English
- Hindi

**COURSES & CERTIFICATIONS**
- *Infosys Certified Big Data Developer*
- *Infosys Certified Spark Professional*
- *Infosys Certified Python Programmer*

**WORK EXPERIENCE**

**Big Data Engineer at Infosys**
*April 2021 to Present*

1. **Project: POLO Ralph Lauren (March '22 - Present)**
   - **Data Reconciliation**
     - *Business Impact*: Identified data loss between source & target.
     - *Responsibilities*: Performed ETL processes on source data and generated variance reports by comparing source and target data.
     - *Technologies Used*: Python, AWS S3, AWS Redshift, Apache Airflow, SQL, PySpark
   - **S3 as a DB**
     - *Business Impact*: Achieved cost savings and performance improvements.
     - *Responsibilities*: Migrated non-transactional data from Aurora to S3 with partitioning. Modified and incorporated AWS S3 into the framework's code, replacing Aurora based on the new partitioned data.
     - *Technologies Used*: AWS Aurora, AWS S3, Python
   - **Automate Service NOW Incident**
     - *Business Impact*: Reduced human effort and dependency.
     - *Responsibilities*: Automated the creation of incidents using SNOW RESTful APIs, reducing manual intervention.
     - *Technologies Used*: Service NOW, Python

2. **Project: Edeka Digital (April '21 - March '22)**
   - **Data Ingestion**
     - *Responsibilities*: Managed data ingestion processes, fetching data, performing operations, and creating reports based on business rules.
     - *Technologies Used*: Python, PySpark, SQL, Azure Databricks

*January 2021 to March 2021*
**Big Data Trainee at Infosys**
Received training in a comprehensive stack, including Hadoop, MapReduce Programming, HIVE, Scala, Apache Spark, Python, and PySpark.

**LINKS**
- [LinkedIn Profile](https://www.linkedin.com/in/prakhar-srivastava-9334a7185/)
- [Medium Blog](https://medium.com/@prakhar740)
- [GitHub Profile](https://github.com/pra-sri)
